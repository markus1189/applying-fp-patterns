* Prelude
#+BEGIN_SRC elisp
(define-minor-mode org-presentation-mode
  "Toggle org presentation mode."
  :init-value nil
  :lighter: " P"
  :group 'org-pres)

(defvar org-presentation-mode-map
  (let ((map (make-sparse-keymap)))
    (define-key map (kbd "<prior> <prior>") 'org-presentation-prev)
    (define-key map (kbd "<next> <next>") 'org-presentation-next)
    (define-key map (kbd "<prior> <next> <next>") (Λ (org-next-block 1)
                                                     (recenter-top-bottom 0)
                                                     (message "Evaluating...")
                                                     (org-ctrl-c-ctrl-c)
                                                     (message "done!")
                                                     (org-display-inline-images)))
    (define-key map (kbd "<next> <prior> <prior>") 'org-previous-block)
    (define-key map (kbd "q") (Λ (org-presentation-mode -1)
                                 (text-scale-set 0)))
    map))

(defun org-presentation-next (arg)
  (interactive "p")
  (progn
    (widen)
    (org-next-visible-heading arg)
    (org-narrow-to-subtree)))

(defun org-presentation-prev (arg)
  (interactive "p")
  (progn
    (widen)
    (org-previous-visible-heading arg)
    (org-narrow-to-subtree)))

(flyspell-mode nil)
(org-babel-remove-result-one-or-many '(4))
(org-cycle '(64))
(setq org-confirm-babel-evaluate nil)
(text-scale-set 7)
(org-display-inline-images)
(blink-cursor-mode -1)
(org-presentation-mode)
#+END_SRC

#+RESULTS:
: t

* Welcome at Scala User Group Düsseldorf:
#+BEGIN_SRC elisp
(play-sound-file-async "sounds/intro.mp3")
(sit-for 5.5)
(play-sound-file-async "sounds/intro2.mp3")
(shell-command-to-string "figlet -f slant -w 70 -c -k \"Applying FP Patterns\"")
#+END_SRC

* Introduction (Why are we even here)

- Functional Programming is getting more and more momentum
- There exist many useful patterns from FP
- Today: Two Patterns from FP

1) Monoids
2) Functional Error Handling
* But before we start some basic knowledge:

-> Who knows about

 -> free adjoint functors?
 -> star-autonomous categories?
 -> geometric morphisms?

* Functional Programming != scary

Good! You don't need them anyway.


                             ¯\_(ツ)_/¯

* What then is FP? (for _me_!)

1) Composability
2) Leverage the type system
3) Referential Transparency (immutability, limit side effects, etc.)

* Some technicality before we start

#+BEGIN_SRC scala
import scala.concurrent._
import scala.concurrent.duration._
import scala.concurrent.ExecutionContext.Implicits.global
import cats._, cats.kernel._, cats.data._, cats.implicits._, cats.syntax.all._
import scala.util.Try
#+END_SRC

* We will use 'cats'

#+BEGIN_QUOTE
Lightweight, modular, and extensible library for functional programming.
#+END_QUOTE

 - 0.7.0 currently released
 - Github: https://github.com/typelevel/cats
 - Guide: http://typelevel.org/cats/
 - Scaladoc: http://typelevel.org/cats/api/#package

* Plan for today

1) Write composable Spark Programs
2) Error handling, the functional way

- repository: http://github.com/markus1189/fp-with-cats

* Composability - OO



                           [[./pics/duplo.jpg]]

* Composability - FP


       [[./pics/lego.jpg]]

* Combining stuff (Monoid)

Can you spot a pattern here?

#+BEGIN_SRC scala
val add = (0       + 1      )  + 5
val mul = (1       * 2      )  * 5
val cat = (List() ++ List(1)) ++ List(2,3)
#+END_SRC

* Abstracting with Monoids

#+BEGIN_SRC scala
def empty1: Int       = 0
def empty2: Int       = 1
def empty3: List[Int] = List()

val add = (empty1 |+| 1      ) |+| 5
val mul = (empty2 |+| 2      ) |+| 5
val mul = (empty3 |+| List(1)) |+| List(2,3)
#+END_SRC

* Definition of Monoids

The Monoid type class:
#+BEGIN_SRC scala
trait Monoid[A] {
  def empty: A
  def combine(x: A, y: A): A
}

implicit class MonoidOps[A](val self: A) {
  // Normally |+| but that would clash
  def +|+(other: A)(implicit M: Monoid[A]) =
    M.combine(self,other)
}
#+END_SRC


* Monoid Rules

Implementations have to obey some rules:

#+BEGIN_EXAMPLE
1) empty |+| x === x                        (Left identity)

2) x |+| empty === x                        (Right identity)

3) (x |+| y) |+| z === x |+| (y |+| z)      (Associativity)
#+END_EXAMPLE

* Let's define some Monoids

1) Addition
2) Multiplication
3) List concatenation

#+BEGIN_SRC scala
implicit val intPlus: Monoid[Int] = new Monoid[Int] {
  override def empty: Int = 0
  override def combine(x: Int, y: Int): Int = x + y
}

1 +|+ 41
#+END_SRC

#+BEGIN_SRC scala
implicit val doubleMul: Monoid[Double] = new Monoid[Double] {
  override def empty: Double = 1
  override def combine(x: Double, y: Double): Double = x * y
}

8.0 +|+ 5.25
#+END_SRC

#+BEGIN_SRC scala
implicit def listConcat[A]: Monoid[List[A]] = new Monoid[List[A]] {
  override def empty: List[A] = List()
  override def combine(x: List[A], y: List[A]): List[A] = x ++ y
}

List(1,2,3) +|+ List(4,5,6)
#+END_SRC

* Monoids can be combined

We can build monoids from monoids:

#+BEGIN_SRC scala
implicit def option[A:Monoid] = new Monoid[Option[A]] {
  def empty = None

  def combine(x: Option[A], y: Option[A]) = (x,y) match {
    case (Some(xx),Some(yy)) => Some(xx +|+ yy)
    case (Some(xx),None) => Some(xx)
    case (None,Some(yy)) => Some(yy)
    case (None,None) => None
  }
}
#+END_SRC

#+BEGIN_SRC scala
val none: Option[Int] = None
Option(2) +|+ Option(40)
Option(8.0) +|+ Option(5.25)
Option(List(1,2,3)) +|+ Option(List(0))
Option(1) +|+ none
none +|+ Option(42)
none +|+ none
#+END_SRC

* Monoids everywhere

#+BEGIN_SRC scala
1 |+| 2
Await.result(Future("a") |+| Future("b"), Duration.Inf)
Option("Hello, ") |+| Option("World")
Map(1->List('a','b')) |+| Map(1->List('c'),2->List())
#+END_SRC

Also:

  - ~Order[A]~
  - ~Either[A,B]~ if Monoid[B]
  - ~A => B~      if Monoid[B]
  - ~Map[A,B]~    if Monoid[B]
  - ~(A,B)~       if Monoid[A] and Monoid[B]

* Functions for monoids

- cats also defines many other functions for monoids
  - specialized ~fold~ with start and combine function
  - Validated (error accumulation)
  - and many more

- at this point you might be thinking:

* Monoids for the real world

#+BEGIN_SRC sh :results raw
echo "[[file:pics/skeptical.jpg]]"
#+END_SRC


* Apache Spark

Task: calculate statistics with Apache Spark

  a) number of words
  b) word count per word
  c) average word length
  +) make it easy to extend

Easy? Only do *one* traversal over the input

(back to cats)

* Several hours later...

TODO: Maybe add the normal version without monoids here

* Apache Spark - Using Monoids

#+BEGIN_SRC scala
// Monoid for Map, Option & Integer addition

def step(word: String) = (1,Map(word->1),word.length)

val data = sc.textFile(file).flatMap(_.split("""\s+""")).map(step)

val z = Monoid.empty[(Int,Map[String,Int],Int)]

val (words,wordCount,chars) = data.fold(z)(_ |+| _)
val averageWordLength = chars / words
#+END_SRC

#+BEGIN_EXAMPLE
1) "FP in cats in düsseldorf"

2) List("FP","in","cats","in","düsseldorf")

3) List((1,Map("FP"->1),2),(1,Map("in"->1),2),
        (1,Map("cats"->1),4),(1,Map("in"->1),2), ...)

4) (5,Map("FP"->1,"in"->2,"cats"->1,...),17)
#+END_EXAMPLE

Remember the requirement: /easy/ extension!
Let's also calculate maximum word length
* Apache Spark - Extension: Max word length

#+BEGIN_SRC scala
// define Monoid instance for Max

def step(word: String) =
  (1,Map(word->1),word.length,Option(Max(word.length)))

val data = sc.textFile(file).flatMap(_.split("""\s+""")).map(step)

val z = Monoid.empty[(Int,Map[String,Int],Int,Option[Max[Int]])]

val (words,wordCount,chars,max) = data.fold(z)(_ |+| _)
val averageWordLength = chars / words
#+END_SRC

* Exercise for later:

1) define the max/min monoid
2) define the option monoid
3) omit word count for "a","an","the"
4) hard: add a counter for words with even length

* Apache Spark Section Done

?QUESTIONS?

* Functional Error Handling

- traditional error handling from java:
  try/catch/finally
- in FP, try to capture exceptions in the types
- slightly better in standard Scala: Try and Either
- but to really get the benefits, use cats/scalaz

* Example: Pokémons

#+BEGIN_SRC scala
case class Pokemon(id: Int, typ: Type)
sealed trait Type extends Product with Serializable
case object Fire extends Type
case object Water extends Type
case object Grass extends Type

class PokemonOwner(name: String)

class PokemonRepository {
  def find(id: Int): Future[Pokemon]
  def delete(id: Int, owner: PokemonOwner)
  def save(p: Pokemon): Future[Unit]
}

def transfer(from: PokemonOwner, to: PokemonOwner): Future[Unit]
#+END_SRC

* Problems:

- Does ~transfer~ throw an exception?
- What about ~find~ / ~save~ etc?
- What *kind* of errors can occur?

* More Functional Way

#+BEGIN_SRC scala
case class Pokemon(id: Int, typ: Type)
sealed trait Type extends Product with Serializable
case object Fire extends Type
case object Water extends Type
case object Grass extends Type

class PokemonOwner(name: String)

class PokemonRepository {
  def find(id: Int, owner: PokemonOwner): Future[Xor[DriverException,Pokemon]]
  def delete(id: Int, owner: PokemonOwner): Future[Xor[DriverException,Unit]]
  def save(p: Pokemon, owner: PokemonOwner): Future[Xor[DriverException,Unit]]
}

def transfer(
  id: Int,
  from: PokemonOwner,
  to: PokemonOwner
): Future[Xor[Throwable,Unit]] = for {
  p <- repo.find(id, from)
  _ <- repo.delete(id, from)
  _ <- repo.save(p, to)
} yield ()
#+END_SRC

* The end

#+BEGIN_SRC elisp
(play-sound-file-async "sounds/intro.mp3")
(sit-for 5.5)
(play-sound-file-async "sounds/intro2.mp3")
(shell-command-to-string "figlet -d fonts -f doom -w 70 -c -k \"The End\"")
#+END_SRC


* Questions
#+BEGIN_SRC sh :results raw
echo "[[file:pics/questions.png]]"
#+END_SRC


* Local words
#  LocalWords:  adjoint functors monoids morphisms
